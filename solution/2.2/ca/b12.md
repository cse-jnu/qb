# Solution of Question-1

### (a) Define the terms “Elapsed time”, “CPU Execution Time” and “Terminate and Stay Resident”.

1. **Elapsed time**: The total time taken from the initiation to the completion of a process, including all delays, input/output operations, and other overheads.
2. **CPU Execution Time**: The time taken by the CPU to execute the instructions of a process, excluding input/output operations and other delays.
3. **Terminate and Stay Resident**: Refers to a type of program that, after execution, does not fully terminate but stays resident in memory for possible future execution.

### (b) A program is running on a specific machine with the following parameters:

- **Total Instruction Count**: 10,000,000 instructions
- **Average CPI**: 2.5 cycles/instruction
- **CPU Clock Rate**: 200 MHz

To calculate the **execution time**, we can use the formula:

$$
\text{Execution time} = \frac{\text{Total Instruction Count} \times \text{CPI}}{\text{Clock Rate}}
$$

Substitute the given values:

$$
\text{Execution time} = \frac{10,000,000 \times 2.5}{200 \times 10^6}
$$

This will give you the execution time in seconds.

### (c) Differentiate between “Program Counter” and “Instruction Register”.

1. **Program Counter (PC)**: Holds the address of the next instruction to be fetched from memory and executed by the CPU.
2. **Instruction Register (IR)**: Holds the current instruction that is being executed by the CPU after it is fetched from memory.

### (d) Can’t we make CPU faster with a faster clock? Why does the clock cycle play a crucial role in a sequential circuit?

- **CPU speed and clock**: While a faster clock can make a CPU execute instructions faster, it is not the only factor. The CPU’s architecture, instruction set, and how it handles different types of instructions also play a role. The clock cycle is crucial because it determines the rate at which the CPU can perform actions, including fetching, decoding, and executing instructions. If the CPU is not optimized for handling complex operations within each clock cycle, merely increasing the clock speed will not lead to significant performance improvements.

### (e) How Shift Left Logical (SLL) instruction can be used as multiplication in MIPS?

- The **Shift Left Logical (SLL)** instruction in MIPS can be used to multiply a value by powers of 2. Shifting a number to the left by `n` positions is equivalent to multiplying that number by $2^n$. For example, shifting a value by 2 positions (SLL 2) multiplies the value by 4.

---

# Solution of Question-2

### (a) What are the conventions for function arguments, results, and point of return address in MIPS?

1. **Function Arguments**: In MIPS, the first four arguments are passed through registers **\$a0** to **\$a3**. If there are more than four arguments, they are passed on the stack.
2. **Results**: The function's return value is stored in register **\$v0** (for integer or address results) and **\$v1** (for additional results, if needed).
3. **Point of Return Address**: The return address, which is the address of the instruction to return to after the function call, is stored in the **\$ra** (return address) register. The `jal` instruction is used to call a function, and the return address is automatically stored in **\$ra**.

### (b) What is the drawback of 1's complement representation? Explain with an example.

- **Drawback of 1's complement**:

  - **Two representations for zero**: In 1’s complement, both positive zero and negative zero can exist. This results in redundancy and complicates arithmetic operations.
  - **Example**:

    - In 8-bit 1’s complement, positive zero is represented as `00000000`, while negative zero is represented as `11111111`.
    - This dual representation of zero can lead to unnecessary complexity in comparison and arithmetic operations, especially in systems that need to handle large amounts of data.

### (c) Differentiate between "Preserved Across Procedure Call" and "Not Preserved Across Procedure Call".

1. **Preserved Across Procedure Call**:

   - These are registers that must retain their values after a function call. The caller expects the callee (the called function) not to change these values. These registers are typically saved by the callee if they need to use them. For example, registers **\$s0** to **\$s7** are preserved across procedure calls in MIPS.

2. **Not Preserved Across Procedure Call**:

   - These are registers that can be modified by the callee function. The caller does not expect these registers to maintain their values after the function call. If the caller needs their values to be retained, it must save them before the call. Registers like **\$t0** to **\$t9** are not preserved across procedure calls.

---

# Solution of Question-3

### (a) Define Hit Rate and Miss Penalty.

1. **Hit Rate**: The percentage of memory accesses that result in a successful retrieval from the cache (i.e., the data is already in the cache).
2. **Miss Penalty**: The time taken to retrieve data from main memory when a cache miss occurs, which includes the time taken to load the data into the cache.

### (b) Differentiate between Temporal Reference and Spatial Reference.

1. **Temporal Reference**:

   - Refers to accessing the same memory location multiple times within a short time period. Temporal locality suggests that if a memory location was accessed recently, it is likely to be accessed again soon.
   - **Example**: Accessing an array element multiple times within a loop.

2. **Spatial Reference**:

   - Refers to accessing memory locations that are close to each other. Spatial locality suggests that if a memory location is accessed, nearby locations are likely to be accessed soon.
   - **Example**: Accessing consecutive elements of an array.

| **Concept**          | **Temporal Reference**                                                              | **Spatial Reference**                                              |
| -------------------- | ----------------------------------------------------------------------------------- | ------------------------------------------------------------------ |
| **Definition**       | Refers to accessing the same memory location multiple times in a short time period. | Refers to accessing memory locations that are close to each other. |
| **Type of Locality** | Temporal Locality                                                                   | Spatial Locality                                                   |
| **Example**          | Accessing the same element of an array multiple times in a loop.                    | Accessing consecutive elements of an array.                        |
| **Characteristic**   | Data is likely to be reused soon after it is first accessed.                        | Data near the accessed location is likely to be accessed soon.     |

### (c) Differentiate between addressing mode and instruction type with appropriate example.

1. **Addressing Mode**:

   - Refers to the way in which the operands of an instruction are specified. It defines how the address of an operand is calculated.
   - **Example**: In **Immediate Addressing Mode**, the operand is directly specified in the instruction itself.
   - **Example**: `ADD R1, R2, #10` (The immediate value `10` is the operand).

2. **Instruction Type**:

   - Refers to the category or classification of an instruction based on the operation it performs.
   - **Example**: An **Arithmetic Instruction** like `ADD`, which performs arithmetic operations, or a **Data Movement Instruction** like `MOV`, which moves data between registers.

| **Concept**       | **Addressing Mode**                                            | **Instruction Type**                                               |
| ----------------- | -------------------------------------------------------------- | ------------------------------------------------------------------ |
| **Definition**    | Refers to the method of specifying operands in an instruction. | Refers to the category or classification of an instruction.        |
| **Purpose**       | Determines how the address of an operand is calculated.        | Defines the operation the instruction performs.                    |
| **Example**       | Immediate Addressing Mode (`ADD R1, R2, #10`).                 | Arithmetic Instruction (`ADD`), Data Movement Instruction (`MOV`). |
| **Functionality** | Helps in locating or computing the operand address.            | Specifies the kind of operation to perform.                        |

### (d) Define spilling? What are the reasons behind spilling?

1. **Spilling**:

   - Spilling occurs when there are not enough registers to hold all the variables needed during the execution of a program. As a result, some variables are moved to memory, which can slow down performance.

2. **Reasons for Spilling**:

   - **Insufficient Registers**: If the number of available registers is smaller than the number of variables needed.
   - **High Register Pressure**: When many variables need to be stored in registers at the same time.
   - **Complex Function Calls**: When a function requires more registers than are available, causing spilling to memory.
   - **Large Number of Variables**: In programs with many local variables or in the presence of deep nested loops, spilling may occur to accommodate all variables.

---

# Solution of Question-4

### (a) Define Cache miss. Briefly explain how cache misses are handled.

- **Cache Miss**: A cache miss occurs when the requested data is not found in the cache, causing the processor to access the slower main memory to fetch the required data.
- **Handling Cache Misses**: When a cache miss occurs, the processor fetches the data from the main memory and stores it in the cache for future accesses. The cache's replacement policy (such as LRU - Least Recently Used) determines which existing cache entry will be replaced by the new data.

### (b) How many total bits are required for a direct-mapped cache with 64KB of data and one-word blocks, assuming a 32-bit address?

To calculate the total number of bits, we need to determine three things:

1. **Block Offset bits**: These are the bits required to address a word within a block.

   - Since each block is one word, the block offset is 0 bits.

2. **Index bits**: These are the bits used to index into the cache.

   - Cache size = 64 KB = 64 × 1024 bytes = 65536 bytes.
   - With one word per block (4 bytes), the number of blocks = $\frac{65536}{4} = 16384$ blocks.
   - Number of index bits = $\log_2 16384 = 14$ bits.

3. **Tag bits**: These are the bits used to uniquely identify a cache line.

   - Address size = 32 bits.
   - Tag bits = Total address bits - (Index bits + Block offset bits) = $32 - 14 - 0 = 18$ bits.

Thus, the total number of bits required = **Tag bits + Index bits + Block offset bits** = $18 + 14 + 0 = 32$ bits.

### (c) Assume there are three small caches, each consisting of four one-word blocks. One cache is fully associative, a second is two-way set associative, and the third is direct-mapped. Find the number of misses for each cache organization given the following sequence of block addresses: 1, 7, 6, 5, 1, and 7.

Let’s evaluate each type of cache:

1. **Fully Associative Cache**:

   - In a fully associative cache, any block can be placed in any cache line.
   - Sequence of addresses: **1, 7, 6, 5, 1, 7**.
   - Initially, the cache is empty, so the first access to address 1 is a miss, and the block is loaded into the cache.
   - Next, address 7 causes a miss and is stored in the cache.
   - Address 6 causes a miss, and the block is stored in the cache.
   - Address 5 causes a miss, and the block is stored in the cache.
   - Address 1 is already in the cache, so it’s a hit.
   - Address 7 is already in the cache, so it’s a hit.
   - **Total Misses = 4**.

2. **Two-Way Set Associative Cache**:

   - In this cache, there are 2 lines per set, and blocks are mapped to sets.
   - Sequence of addresses: **1, 7, 6, 5, 1, 7**.
   - Initially, all sets are empty, so:

     - Address 1 causes a miss and is placed in a set.
     - Address 7 causes a miss and is placed in the other line of the same set.
     - Address 6 causes a miss and is placed in a new set.
     - Address 5 causes a miss and replaces an existing block in a set (since there are only 2 lines per set).
     - Address 1 is in the cache, so it's a hit.
     - Address 7 is in the cache, so it's a hit.

   - **Total Misses = 4**.

3. **Direct-Mapped Cache**:

   - In a direct-mapped cache, each block has a specific line it must be stored in.
   - Sequence of addresses: **1, 7, 6, 5, 1, 7**.
   - Initially, all lines are empty, so:

     - Address 1 causes a miss and is loaded into the cache.
     - Address 7 causes a miss and is loaded into the cache.
     - Address 6 causes a miss and is loaded into the cache.
     - Address 5 causes a miss and replaces address 1 (because of the direct mapping).
     - Address 1 causes a miss again and is loaded into the cache, replacing address 6.
     - Address 7 is already in the cache, so it’s a hit.

   - **Total Misses = 5**.

### Final Results:

- **Fully Associative Cache**: 4 misses
- **Two-Way Set Associative Cache**: 4 misses
- **Direct-Mapped Cache**: 5 misses

---

# Solution of Question-5


### (a) Differentiate between precision and accuracy with an example.

1. **Precision**:

   - Refers to the consistency or repeatability of measurements. If a measurement process consistently produces similar results, it is considered precise.
   - **Example**: If you measure a length of 5 cm five times and get values of 5.1 cm, 5.0 cm, 5.1 cm, 5.0 cm, and 5.1 cm, the measurements are precise because they are close to each other, but not necessarily accurate.

2. **Accuracy**:

   - Refers to how close a measured value is to the true or target value. If a measurement is close to the actual value, it is accurate.
   - **Example**: If the true length is 5 cm, and your measurements are 5.0 cm, 4.9 cm, 5.1 cm, 5.0 cm, and 5.1 cm, the measurements are accurate because they are close to the true value, but may not be very precise if they vary significantly.

### (b) What decimal number is represented by this single precision float?

The binary sequence you provided represents a 32-bit single precision floating-point number in IEEE 754 format. Let’s break down the binary sequence:

**IEEE 754 single precision format**:

- **1 bit for sign** (S)
- **8 bits for exponent** (E)
- **23 bits for the fraction/mantissa** (M)

Binary sequence:
`1 10000000 100100100001111110110101`

Let’s decode it:

1. **Sign bit (S)** = `1`: This means the number is negative.
2. **Exponent bits (E)** = `10000000`: This is `128` in decimal. In IEEE 754, the exponent is biased by 127, so the actual exponent is `128 - 127 = 1`.
3. **Mantissa bits (M)** = `10010010000111111011010`: This is the fraction part of the number, where an implicit leading 1 is assumed in normalized numbers. So, the mantissa is `1.10010010000111111011010`.

Now, we can compute the decimal value:

- The value is given by the formula:

  $$
  (-1)^{S} \times (1 + \text{Mantissa}) \times 2^{E}
  $$

Substituting the values:

$$
(-1)^{1} \times (1 + 0.10010010000111111011010) \times 2^1
$$

$$
-1 \times 1.10010010000111111011010 \times 2
$$

$$
-2.20020040000399922182980
$$

Thus, the decimal number represented by this single precision float is approximately **-2.2002**.

### (c) Convert the following number in IEEE single-precision format to the decimal format:

Binary number: `11000000.010...0000`

Let's break this down into IEEE 754 single-precision format:

**IEEE 754 single precision format**:

- **1 bit for the sign (S)**
- **8 bits for the exponent (E)**
- **23 bits for the fraction/mantissa (M)**

For the given binary number `11000000.010...0000`, we assume that the `...0000` part has 23 bits of zeroes.

#### Step 1: Break the number into IEEE 754 format

1. **Sign bit (S)**: The first bit is `1`, so it’s negative.
2. **Exponent (E)**: The next 8 bits are `10000000`. This represents the number 128 in decimal.

   - In IEEE 754 format, the exponent is stored with a bias of 127. So, the actual exponent is `128 - 127 = 1`.

3. **Mantissa (M)**: The next 23 bits are `010...0000`, which corresponds to `1.01` in binary, as there is an implicit leading 1.

#### Step 2: Calculate the decimal value

The number is calculated using the formula:

$$
(-1)^S \times (1 + \text{Mantissa}) \times 2^{E}
$$

Substitute the values:

$$
(-1)^1 \times (1 + 0.01) \times 2^1
$$

$$
-1 \times 1.01 \times 2
$$

$$
-2.02
$$

Thus, the decimal equivalent of `11000000.010...0000` is **-2.02**.

### (d) Use the Booth's algorithm to multiply 7 (multiplicand) and -3 (multiplier), where each number is represented using 4 bits.

**Booth’s Algorithm** is used for multiplication of binary numbers, especially when the numbers can be both positive and negative. It’s based on examining pairs of bits and making decisions about addition or subtraction depending on the values of the bits.

#### Step 1: Convert 7 and -3 into 4-bit binary format

- **7 (multiplicand)** in 4-bit signed binary: `0111`
- **-3 (multiplier)** in 4-bit signed binary (using two’s complement): `1101`

#### Step 2: Set up the Booth’s algorithm

We need to consider the multiplicand and multiplier with the extra bits added for the calculation process. Booth’s algorithm involves using:

- **Q (Multiplier)**: `1101` (4 bits)
- **Q-1 (Extra bit, initially set to 0)**: `0`
- **M (Multiplicand)**: `0111`
- **-M (Negative of Multiplicand)**: Two’s complement of `0111` is `1001`.

We follow the steps of Booth’s algorithm by checking the bits of Q and Q-1, performing additions or subtractions, and shifting the bits. Without delving into all the detailed steps, here's the final result using Booth's algorithm:

#### Final result:

- The result of multiplying 7 (`0111`) by -3 (`1101`) is `10001011` in binary, which corresponds to **-21** in decimal.

---

# Solution of Question-6

### (a) Define addressing mode. Classify and explain each of the addressing modes.

**Addressing Mode** refers to the method used to specify the operand (data) of an instruction in a CPU. It defines how the location of an operand is determined or accessed during the execution of an instruction. Addressing modes are used to simplify and increase the flexibility of instruction sets.

#### Types of Addressing Modes:

1. **Immediate Addressing Mode**:

   - The operand is specified explicitly in the instruction itself.
   - **Example**: `MOV R0, #5` — the immediate operand `5` is directly given.

2. **Register Addressing Mode**:

   - The operand is located in a register.
   - **Example**: `MOV R0, R1` — the value in register `R1` is moved to register `R0`.

3. **Direct Addressing Mode**:

   - The address of the operand is given directly in the instruction.
   - **Example**: `MOV R0, 1000` — the value at memory address `1000` is loaded into `R0`.

4. **Indirect Addressing Mode**:

   - The instruction specifies a memory location that holds the address of the operand.
   - **Example**: `MOV R0, (R1)` — the value at the memory address stored in `R1` is loaded into `R0`.

5. **Indexed Addressing Mode**:

   - The address of the operand is generated by adding a constant (displacement) to the contents of a register.
   - **Example**: `MOV R0, 1000(R1)` — the value at the memory address `1000 + R1` is loaded into `R0`.

6. **Base Register Addressing Mode**:

   - Similar to indexed, but uses a base register to point to a specific segment of memory, with an offset.
   - **Example**: `MOV R0, 4(R1)` — the address is calculated as `R1 + 4`.

7. **Relative Addressing Mode**:

   - The operand’s address is determined by adding an offset to the program counter (PC).
   - **Example**: `JUMP 10` — the jump occurs 10 bytes from the current program counter.

### (b) Draw and explain the IAS structure of a first-generation computer.

The **IAS (Institute for Advanced Study) Computer** was one of the first stored-program computers, developed by John von Neumann. It had a basic architecture with the following components:

- **Control Unit (CU)**: Directs the operation of the processor by interpreting instructions and controlling the flow of data.
- **Arithmetic Logic Unit (ALU)**: Performs arithmetic and logical operations.
- **Memory**: Stores both data and instructions. In the IAS model, memory was a single unit that stored data and program instructions.
- **Input/Output**: Interfaces for receiving data from and sending data to the external environment.

The IAS machine used **binary arithmetic** and **stored-program architecture**, where both instructions and data were stored in memory. The basic structure is:

- **Accumulator Register (AC)**: Holds the result of operations.
- **Program Counter (PC)**: Holds the address of the next instruction to be executed.
- **Memory**: Divided into multiple cells, each storing 40 bits (in the original IAS machine).

The architecture operated by fetching an instruction, decoding it, executing it, and then updating the PC to the next instruction. It was a key model for later computers.

### (c) Differentiate between address and data bus.

1. **Address Bus**:

   - **Purpose**: Carries the address of the memory location from the CPU to the memory or I/O devices.
   - **Direction**: Unidirectional (data flows only from the CPU to memory or devices).
   - **Size**: The width of the address bus (number of lines) determines the maximum addressable memory.
   - **Example**: If the address bus is 16 bits wide, the CPU can access 2^16 addresses (i.e., 65536 memory locations).

2. **Data Bus**:

   - **Purpose**: Carries the actual data between the CPU and memory or I/O devices.
   - **Direction**: Bidirectional (data can flow both to and from the CPU).
   - **Size**: The width of the data bus (number of lines) determines how much data can be transferred at once. For example, an 8-bit data bus can transfer 1 byte of data at a time.
   - **Example**: The CPU uses the data bus to send data to memory or retrieve data from memory.

In summary:

- **Address Bus**: Specifies the location (address) of data.
- **Data Bus**: Carries the actual data to/from the location.

---

# Solution of Question-7

### (a) Explain the basic functions of a processor.

The **basic functions of a processor** (also known as the CPU) are as follows:

1. **Fetch**: The processor retrieves an instruction from memory, using the program counter (PC) to find the address of the instruction.
2. **Decode**: The retrieved instruction is decoded to determine the operation to be performed (e.g., addition, subtraction, etc.).
3. **Execute**: The processor performs the operation specified by the decoded instruction, using its arithmetic logic unit (ALU) or other functional units.
4. **Store**: The result of the execution is stored in a register or memory, as needed, before moving to the next instruction.

### (b) What are the architectural extension mechanisms for a processor?

Architectural extension mechanisms for a processor are techniques used to enhance the processor's capabilities, either by increasing the performance or providing additional features. Some of these mechanisms include:

1. **SIMD (Single Instruction, Multiple Data)**: Allows a single instruction to operate on multiple data elements simultaneously.
2. **Multithreading**: Involves executing multiple threads on a single processor to improve efficiency.
3. **Pipelining**: Involves breaking down an instruction into multiple stages (e.g., fetch, decode, execute), enabling multiple instructions to be processed at once in different stages.
4. **Superscalar Architecture**: Allows multiple instructions to be processed simultaneously in one clock cycle.
5. **Vector Processing**: Extends the processor to handle vector operations for scientific computing tasks.
6. **Out-of-Order Execution**: The processor can execute instructions as resources become available, rather than strictly in the order they appear in the program.
7. **Memory Management Units (MMU)**: Adds virtual memory support to processors, allowing for larger address spaces and memory protection.

### (c) Draw and explain the operations of an accumulator-based processor with extension features.

An **accumulator-based processor** typically uses a single register (the accumulator) to perform operations. Here’s a simplified explanation of its operation:

1. **Input data** is loaded into the **accumulator** (AC).
2. An operation (e.g., addition, subtraction, etc.) is performed between the **accumulator** and another value (from memory or another register).
3. The result of the operation is stored back in the **accumulator**.
4. The accumulator continuously holds intermediate results for subsequent operations.

**Extended Features**:

- With extensions such as **pipelining** and **multithreading**, the processor can hold multiple intermediate results or perform simultaneous operations across different parts of the processor.

### (d) Write down the operation for an accumulator-based processor for the operation: `Z = X + Y`.

Here’s how this would work on an accumulator-based processor:

1. **Load X** into the accumulator (AC): `AC = X`
2. **Add Y** to the value in the accumulator: `AC = AC + Y` (i.e., `AC = X + Y`)
3. **Store the result** from the accumulator into the variable Z: `Z = AC`

This is a simple implementation of the operation where the **accumulator** holds the intermediate result of the addition before it is transferred to the output.

---

# Solution of Question-8

### (a) Explain with both figure and MIPS code how elements are pushed into and popped out from the stack.

#### Stack Operation:

- **Push**: Pushing an element onto the stack involves storing the data at the current top of the stack and then adjusting the stack pointer (SP) to the next available location.
- **Pop**: Popping an element from the stack involves removing the top element and adjusting the stack pointer to point to the next element.

#### MIPS Code Example:

- **Push Operation**:

  ```mips
  # Assume the data to be pushed is in $t0 and stack pointer is in $sp
  sub $sp, $sp, 4         # Decrease the stack pointer (moving to next available space)
  sw $t0, 0($sp)          # Store the data from $t0 into the location pointed by $sp
  ```

- **Pop Operation**:

  ```mips
  lw $t0, 0($sp)          # Load the data from the top of the stack into $t0
  add $sp, $sp, 4         # Increase the stack pointer (moving to the previous element)
  ```

#### Figure Explanation:

1. Initially, the stack pointer (`SP`) points to the top of the stack.
2. **Push**: When pushing, the stack pointer is decremented, and the data is stored at the new position.
3. **Pop**: When popping, the data is retrieved from the current position of the stack pointer, and the pointer is incremented to point to the next element.

### (b) Using the Restoring Division Algorithm, divide Divisor 4 and Dividend 6.

The **Restoring Division Algorithm** is a method used to divide two numbers. Here's a step-by-step explanation for dividing 6 by 4 using this algorithm:

1. **Initial Setup**:

   - Dividend (D) = 6
   - Divisor (Q) = 4
   - We start with two registers: the **dividend** (D) and the **remainder** (R), initialized as:

     - R = 0 (initial remainder)
     - Q = 4 (divisor)

2. **Restoring Division Steps**:

   - **Step 1**: Shift the remainder and the next bit of the dividend into the quotient register.
   - **Step 2**: Subtract the divisor from the remainder.
   - **Step 3**: If the remainder is negative, restore the previous value and set the quotient bit to 0. If the remainder is positive or zero, leave the remainder and set the quotient bit to 1.
   - **Step 4**: Repeat the process for all the bits.

For the values 6 and 4, after going through the restoring division steps, you will find that:

- Quotient = 1
- Remainder = 2

Thus, the result of 6 divided by 4 is 1 with a remainder of 2.

### (c) Convert the real number -27.375 (in base 10) into IEEE 754 binary representation (Single Precision).

To convert **-27.375** to IEEE 754 single precision:

1. **Step 1**: Convert the integer part (27) to binary:

   - 27 in decimal = 11011 in binary.

2. **Step 2**: Convert the fractional part (0.375) to binary:

   - 0.375 × 2 = 0.75 → first bit = 0
   - 0.75 × 2 = 1.5 → second bit = 1
   - 0.5 × 2 = 1.0 → third bit = 1
   - Therefore, 0.375 in binary = 0.011.

3. **Step 3**: Combine the integer and fractional parts:

   - 27.375 in binary = **11011.011**.

4. **Step 4**: Normalize the binary number:

   - 11011.011 = 1.1011011 × 2^4.

5. **Step 5**: Convert to IEEE 754 format:

   - **Sign bit**: 1 (since the number is negative).
   - **Exponent**: 4 (the exponent bias for single precision is 127, so the actual exponent is 4 + 127 = 131, which is 10000011 in binary).
   - **Mantissa**: After the decimal point, take the next 23 bits: 10110110000000000000000.

6. **Step 6**: Put all parts together in IEEE 754 single precision format:

   - Sign bit: 1
   - Exponent: 10000011
   - Mantissa: 10110110000000000000000

Thus, the IEEE 754 single precision representation of **-27.375** is:

```
1 10000011 10110110000000000000000
```

---
